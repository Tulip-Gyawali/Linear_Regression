# Comparison of OLS and Gradient Descent

This repository contains a Jupyter Notebook that compares two widely-used methods for linear regression: **Ordinary Least Squares (OLS)** and **Gradient Descent (GD)**. The goal is to illustrate the difference in approach, computation, and results between these two optimization techniques.

## Contents

- ðŸ“˜ `Comparision_Of_OLS_And_Gradient_Descent.ipynb`: Main notebook with code, explanations, and visualizations.
- ðŸ“ˆ Visual comparison of regression lines generated by both methods.
- ðŸ§® Performance and error analysis using Mean Squared Error (MSE).

## Methods Compared

- **OLS (Closed-form solution)**  
  Computes the optimal weights analytically using the normal equation.

- **Gradient Descent (Iterative optimization)**  
  Starts with random weights and iteratively updates them to minimize the cost function.

## Key Features

- Synthetic dataset generation
- Visual plots of fitted lines
- Iterative convergence plot for gradient descent
- MSE comparison
- Learning rate experimentation

## How to Run

1. Clone this repository:
   ```bash
   git clone https://github.com/yourusername/ols-vs-gradient-descent.git
   cd ols-vs-gradient-descent
